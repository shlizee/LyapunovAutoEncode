# -*- coding: utf-8 -*-
"""Test Set Prep.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tNFk3F5k4DqLjqmVOFwxDeMgfmF79d3b
"""
import sys
import torch
from config import *
import glob
from tqdm import tqdm
import torchvision
import torchvision.transforms as transforms

def process_text(text):
    test_chars= set([c for c in text])
    for c in test_chars:
        if c not in dcon.datasets['char_to_int'].keys():
            text = text.replace(c, '')
    data = torch.ByteTensor(len(text))
    for idx, c in enumerate(text):
        data[idx] = char_map[c]
    return data

def SMNIST():
    train_dataset = torchvision.datasets.MNIST(root='data/',
                                              train=True,
                                              transform=transforms.ToTensor(),
                                              download=False)
    test_dataset = torchvision.datasets.MNIST(root='data/',
                                              train=False,
                                              transform=transforms.ToTensor())
    train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100,
                                                      shuffle=False)
    test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100,
                                                      shuffle=False)
    sequence_length = 28
    input_size = 28
    for i, (images, labels) in enumerate(train_dataloader):
        images = images.reshape(-1, sequence_length * input_size)
        labels = labels
        if i == 0:
            train_data = images
            train_labels = labels
        else:
            train_data = torch.cat([train_data, images])
            train_labels = torch.cat([train_labels, labels])
        # train_labels.append(labels)
    print(i, train_data.shape, train_labels.shape)

    for i, (images, labels) in enumerate(test_dataloader):
        images = images.reshape(-1, sequence_length * input_size)
        labels = labels
        if i == 0:
            test_data = images
            test_labels = labels
        else:
            test_data = torch.cat([test_data, images])
            test_labels = torch.cat([test_labels, labels])
        # train_labels.append(labels)
    print(i, test_data.shape, test_labels.shape)
    dataset = {
        'train_set': [train_data, train_labels],
        'test_set': [test_data, test_labels]
    }
    torch.save(dataset, 'data/MNIST/MNIST_train_test.p')

def charRNN():
    device = torch.device('cpu')
    dcon = torch.load('CharRNN/dcon.p', map_location = torch.device('cpu'))
    seq_length = 100
    batch_size = 32
    full_input_set = torch.ByteTensor(0, batch_size, seq_length - 1)
    full_target_set = torch.ByteTensor(0, batch_size, seq_length - 1)
    char_map = dcon.datasets['char_to_int']

    txt_dir = 'data/'
    text_files = glob.glob(txt_dir+ "*.txt")
    for file in tqdm(text_files):
        f = open(file, 'rt', encoding = 'utf8')
        orig_text = f.read()
        text = orig_text
    #     print(orig_text.split('}} \n \n'))
    #     text = orig_text.split('}} \n \n')[1]

        data = process_text(text)
        target = torch.ByteTensor(len(data))
        for i in range(int(len(data) / seq_length)):
            src_seq = data[i * seq_length : (i + 1) * seq_length]   # length: seq_length
            dest_seq = src_seq.clone()
            dest_seq[0:-1] = src_seq[1:]
            # dest_seq[-1] = src_seq[0]
            target[i * seq_length : (i + 1) * seq_length] = dest_seq

        batches = math.floor((len(data) / (batch_size * seq_length)))
        train_idx = 0   # start point of train set
        input_set = torch.LongTensor(batches, batch_size, seq_length - 1)
        target_set = torch.LongTensor(batches, batch_size, seq_length - 1)
        for i in range(batches):
            for j in range(batch_size):
                start_idx = train_idx + i * (batch_size * seq_length) + j * seq_length
                end_idx = start_idx + seq_length - 1
                input_set[i][j] = data[start_idx : end_idx]
                target_set[i][j] = target[start_idx: end_idx]
    #     print(input_set.shape)
        full_input_set = torch.cat((full_input_set, input_set), dim = 0)
        full_target_set = torch.cat((full_target_set, target_set), dim = 0)

    samples = full_target_set.shape[0]
    split_idx = math.floor(samples*0.8)
    shuffle_idx = torch.randperm(full_target_set.shape[0])
    train_set = (full_input_set[shuffle_idx][:split_idx], full_target_set[shuffle_idx][:split_idx])
    val_set = (full_input_set[shuffle_idx][split_idx:], full_target_set[shuffle_idx][split_idx:])
    data = {'train_set': train_set, 'val_set': val_set, 'char_to_int': char_map}

    torch.save(data, 'data/book_data.p')

if __name__ == '__main__':
    if sys.argv[1] == 'charRNN':
        charRNN()
    elif sys.argv[1] == 'SMNIST':
        SMNIST()
